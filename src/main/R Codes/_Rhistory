#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 8
#Task: Logistic Regression Implementation - Part II
setwd("C:/Users/acer/Documents/MachineLearningLab")
getwd()
train <- read.csv("blooddonation.csv")
nrow(train)
head(train)
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
train <- read.csv("blooddonation.csv")
nrow(train)
head(train)
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 8
#Task: Logistic Regression Implementation - Part II
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
train <- read.csv("blooddonation.csv")
nrow(train)
head(train)
library(caTools)
set.seed(88)
split <- sample.split(train$donate, SplitRatio = 0.75)
#get training and test data
dresstrain <- subset(train, split == TRUE)
dresstest <- subset(train, split == FALSE)
#Logistic Regression Model
model <- glm (donate ~ ., data = dresstrain, family = binomial)
#Summary
summary(model)
#Probability
probability <- predict(model, type = 'response')
#Confusion Matrix (Cut-off value = 0.5)
con_mat <- table(dresstrain$donate, probability > 0.5)
con_mat
#Accuracy
accuracy <- ((con_mat[1, 1] + con_mat[2, 2])/(con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
accuracy
#Precision
precision <- ((con_mat[2, 2]) / (con_mat[1, 2] + con_mat[2, 2])) * 100
precision
#Recall
recall <- (con_mat[2, 2] / (con_mat[2, 1] + con_mat[2, 2])) * 100
recall
#Error Rate
error_rate <- (con_mat[1, 1] / (con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
error_rate
#ROCR Curve
#install.packages('ROCR')
library(ROCR)
ROCRpred <- prediction(probability, dresstrain$donate)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
#Confusion Matrix (Cut-off value = 0.5)
con_mat <- table(dresstrain$donate, probability > 0.5)
con_mat
#Accuracy
accuracy <- ((con_mat[1, 1] + con_mat[2, 2])/(con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
accuracy
#Precision
precision <- ((con_mat[2, 2]) / (con_mat[1, 2] + con_mat[2, 2])) * 100
precision
#Recall
recall <- (con_mat[2, 2] / (con_mat[2, 1] + con_mat[2, 2])) * 100
recall
#Error Rate
error_rate <- (con_mat[1, 1] / (con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
error_rate
#ROCR Curve
#install.packages('ROCR')
library(ROCR)
ROCRpred <- prediction(probability, dresstrain$donate)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
#Confusion Matrix (Cut-off value = 0.2)
con_mat <- table(dresstrain$donate, probability > 0.2)
con_mat
#Accuracy
accuracy <- ((con_mat[1, 1] + con_mat[2, 2])/(con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
accuracy
#Precision
precision <- ((con_mat[2, 2]) / (con_mat[1, 2] + con_mat[2, 2])) * 100
precision
#Recall
recall <- (con_mat[2, 2] / (con_mat[2, 1] + con_mat[2, 2])) * 100
recall
#Error Rate
error_rate <- (con_mat[1, 1] / (con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
error_rate
#ROCR Curve
#install.packages('ROCR')
library(ROCR)
ROCRpred <- prediction(probability, dresstrain$donate)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
#Confusion Matrix (Cut-off value = 0.2)
con_mat <- table(dresstrain$donate, probability > 0.8)
con_mat
#Accuracy
accuracy <- ((con_mat[1, 1] + con_mat[2, 2])/(con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
accuracy
#Precision
precision <- ((con_mat[2, 2]) / (con_mat[1, 2] + con_mat[2, 2])) * 100
precision
#Recall
recall <- (con_mat[2, 2] / (con_mat[2, 1] + con_mat[2, 2])) * 100
recall
#Error Rate
error_rate <- (con_mat[1, 1] / (con_mat[1, 1] + con_mat[1, 2] + con_mat[2, 1] + con_mat[2, 2])) * 100
error_rate
#ROCR Curve
#install.packages('ROCR')
library(ROCR)
ROCRpred <- prediction(probability, dresstrain$donate)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 11
#Task: Multinomial Logistic Regression Implementation
#Task I
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
data_set <- read.csv("glass_multiclass.csv")
head(data_set)
nrow(data_set)
names(data_set)
dim(data_set)
summary(data_set)
data_set$Type <- as.factor(data_set$Type)
library(caTools)
set.seed(88)
split <- sample.split(data_set$Type, SplitRatio = 0.75)
#get training and test data
train <- subset(data_set, split == TRUE)
test <- subset(data_set, split == FALSE)
dim(test)
dim(train)
table(train$Type)
table(test$Type)
#install.packages('nnet')
library("nnet")
model <- multinom(Type ~ ., data = train, maxit = 1000)
summary(model)
predictions_train <- predict(model, train)
con_mat_train_model <- table(predicted = predictions_train, actual = train$Type)
con_mat_train_model
accuracy_train_model <- sum(diag(con_mat_train_model)) / sum(con_mat_train_model)
accuracy_train_model
error_rate_train_model <- 1 - accuracy_train_model
error_rate_train_model
predictions_test <- predict(model, test)
con_mat_test_model <- table(predicted = predictions_test, actual = test$Type)
con_mat_test_model
accuracy_test_model <- sum(diag(con_mat_test_model)) / sum(con_mat_test_model)
accuracy_test_model
error_rate_test_model <- 1 - accuracy_train_model
error_rate_test_model
#Task II
model1 <- multinom(Type ~ RI + Na + Mg, data = train, maxit = 1000)
summary(model1)
predictions_train1 <- predict(model1, train)
con_mat_train_model1 <- table(predicted = predictions_train1, actual = train$Type)
con_mat_train_model1
accuracy_train_model1 <- sum(diag(con_mat_train_model1)) / sum(con_mat_train_model1)
accuracy_train_model1
error_rate_train_model1 <- 1 - accuracy_train_model1
error_rate_train_model1
predictions_test1 <- predict(model1, test)
con_mat_test_model1 <- table(predicted = predictions_test1, actual = test$Type)
con_mat_test_model1
accuracy_test_model1 <- sum(diag(con_mat_test_model1)) / sum(con_mat_test_model1)
accuracy_test_model1
error_rate_test_model1 <- 1 - accuracy_train_model1
error_rate_test_model1
model2 <- multinom(Type ~ RI + Na + Mg + Al + Si + K, data = train, maxit = 1000)
summary(model2)
predictions_train2 <- predict(model2, train)
con_mat_train_model2 <- table(predicted = predictions_train2, actual = train$Type)
con_mat_train_model2
accuracy_train_model2 <- sum(diag(con_mat_train_model2)) / sum(con_mat_train_model2)
accuracy_train_model2
error_rate_train_model2 <- 1 - accuracy_train_model2
error_rate_train_model2
predictions_test2 <- predict(model2, test)
con_mat_test_model2 <- table(predicted = predictions_test2, actual = test$Type)
con_mat_test_model2
accuracy_test_model2 <- sum(diag(con_mat_test_model2)) / sum(con_mat_test_model2)
accuracy_test_model2
error_rate_test_model2 <- 1 - accuracy_train_model2
error_rate_test_model2
model3 <- multinom(Type ~ RI + Na + Mg + Al + Si + K + Ca + Ba +Fe, data = train, maxit = 1000)
summary(model3)
predictions_train3 <- predict(model3, train)
con_mat_train_model3 <- table(predicted = predictions_train3, actual = train$Type)
con_mat_train_model3
accuracy_train_model3 <- sum(diag(con_mat_train_model3)) / sum(con_mat_train_model3)
accuracy_train_model3
error_rate_train_model3 <- 1 - accuracy_train_model3
error_rate_train_model3
predictions_test3 <- predict(model3, test)
con_mat_test_model3 <- table(predicted = predictions_test3, actual = test$Type)
con_mat_test_model3
accuracy_test_model3 <- sum(diag(con_mat_test_model3)) / sum(con_mat_test_model3)
accuracy_test_model3
error_rate_test_model3 <- 1 - accuracy_train_model3
error_rate_test_model3
model4 <- multinom(Type ~ Si + K + Ca + Ba + Fe, data = train, maxit = 1000)
summary(model4)
predictions_train4 <- predict(model4, train)
con_mat_train_model4 <- table(predicted = predictions_train4, actual = train$Type)
#con_mat_train_model4
accuracy_train_model4 <- sum(diag(con_mat_train_model4)) / sum(con_mat_train_model4)
accuracy_train_model4
error_rate_train_model4 <- 1 - accuracy_train_model4
error_rate_train_model4
predictions_test4 <- predict(model4, test)
con_mat_test_model4 <- table(predicted = predictions_test4, actual = test$Type)
#con_mat_test_model4
accuracy_test_model4 <- sum(diag(con_mat_test_model4)) / sum(con_mat_test_model4)
accuracy_test_model4
error_rate_test_model4 <- 1 - accuracy_train_model4
error_rate_test_model4
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
d <- read.csv("iris.csv")
head(d)
nrow(d)
summary(d)
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 12
#Task: Naive Bayes Implementation
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
d <- read.csv("iris.csv")
head(d)
nrow(d)
summary(d)
#converting as a factor to class
d$class=factor(d$class)
#Finding structure of iris data
str(d)
# Creating table for class variable
table(d$class)
sample_iris=sample(150,110,replace = FALSE)
#creating training and test dataset
iris_training=d[sample_iris,]
iris_test=d[-sample_iris,]
#creating levels
iris_training_labels=d[sample_iris,]$class
iris_test_labels=d[-sample_iris,]$class
table(iris_training$class)
table(iris_test$class)
library(e1071)
iris_classifier=naiveBayes(class ~ ., data = iris_training)
class(iris_classifier)
print(iris_classifier)
summary(iris_classifier)
#Evaluvating model performance
iris_test_pred=predict(iris_classifier,iris_test)
iris_test_pred
#install.packages("gmodels")
#library(gmodels)
#CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE, dnn = c('predicted', 'actual'))
conf_matrix <- table(iris_test_pred, iris_test$class)
conf_matrix
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
accuracy
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 12
#Task: Naive Bayes Implementation
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
d <- read.csv("iris.csv")
head(d)
nrow(d)
summary(d)
#converting as a factor to class
d$class=factor(d$class)
#Finding structure of iris data
str(d)
# Creating table for class variable
table(d$class)
sample_iris=sample(150,110,replace = FALSE)
#creating training and test dataset
iris_training=d[sample_iris,]
iris_test=d[-sample_iris,]
#creating levels
iris_training_labels=d[sample_iris,]$class
iris_test_labels=d[-sample_iris,]$class
table(iris_training$class)
table(iris_test$class)
library(e1071)
iris_classifier=naiveBayes(class ~ ., data = iris_training)
class(iris_classifier)
print(iris_classifier)
summary(iris_classifier)
#Evaluvating model performance
iris_test_pred=predict(iris_classifier,iris_test)
iris_test_pred
#install.packages("gmodels")
#library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE, dnn = c('predicted', 'actual'))
conf_matrix <- table(iris_test_pred, iris_test$class)
conf_matrix
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
accuracy
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 12
#Task: Naive Bayes Implementation
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
d <- read.csv("iris.csv")
head(d)
nrow(d)
summary(d)
#converting as a factor to class
d$class=factor(d$class)
#Finding structure of iris data
str(d)
# Creating table for class variable
table(d$class)
sample_iris=sample(150,110,replace = FALSE)
#creating training and test dataset
iris_training=d[sample_iris,]
iris_test=d[-sample_iris,]
#creating levels
iris_training_labels=d[sample_iris,]$class
iris_test_labels=d[-sample_iris,]$class
table(iris_training$class)
table(iris_test$class)
library(e1071)
iris_classifier=naiveBayes(class ~ ., data = iris_training)
class(iris_classifier)
print(iris_classifier)
summary(iris_classifier)
#Evaluvating model performance
iris_test_pred=predict(iris_classifier,iris_test)
iris_test_pred
#install.packages("gmodels")
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE, dnn = c('predicted', 'actual'))
conf_matrix <- table(iris_test_pred, iris_test$class)
conf_matrix
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
accuracy
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 12
#Task: Naive Bayes Implementation
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
d <- read.csv("iris.csv")
head(d)
nrow(d)
summary(d)
#converting as a factor to class
d$class=factor(d$class)
#Finding structure of iris data
str(d)
# Creating table for class variable
table(d$class)
sample_iris=sample(150,110,replace = FALSE)
#creating training and test dataset
iris_training=d[sample_iris,]
iris_test=d[-sample_iris,]
#creating levels
iris_training_labels=d[sample_iris,]$class
iris_test_labels=d[-sample_iris,]$class
table(iris_training$class)
table(iris_test$class)
library(e1071)
iris_classifier=naiveBayes(class ~ ., data = iris_training)
class(iris_classifier)
print(iris_classifier)
summary(iris_classifier)
#Evaluvating model performance
iris_test_pred=predict(iris_classifier,iris_test)
iris_test_pred
#install.packages("gmodels")
#library(gmodels)
conf_matrix <- table(iris_test_pred, iris_test$class)
conf_matrix
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
accuracy
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 13
#Task: k-Nearest Neighbour Implementation
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
data_set <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
stringsAsFactors = FALSE
#head(data_set)
nrow(data_set)
str(data_set)
data_set <- data_set[-1]
str(data_set)
table(data_set$diagnosis)
data_set$diagnosis <- as.factor(data_set$diagnosis)
#Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# One could also use sequence such as df[1:2]
dfNorm <- as.data.frame(lapply(data_set[2:31], normalize))
head(dfNorm)
data_train <- dfNorm[1:400,]
data_test <- dfNorm[401:569,]
data_train_labels <- data_set[1:400, 1]
data_test_labels <- data_set[401:569, 1]
#install.packages("class")
library(class)
data_test_pred <- knn(train = data_train, test = data_test,cl = data_train_labels, k=21)
#summary(data_test_pred)
#install.packages("gmodels")
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq=FALSE)
#Z-score standardization
stad <- function(x) {
return ((x - mean(x)) / sqrt(var(x)))
}
# One could also use sequence such as df[1:2]
dfNorm <- as.data.frame(lapply(data_set[2:31], stad))
head(dfNorm)
data_train <- dfNorm[1:400,]
data_test <- dfNorm[401:569,]
data_train_labels <- data_set[1:400, 1]
data_test_labels <- data_set[401:569, 1]
#install.packages("class")
library(class)
data_test_pred <- knn(train = data_train, test = data_test,cl = data_train_labels, k=21)
#summary(data_test_pred)
#install.packages("gmodels")
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq=FALSE)
install.packages("gmodels")
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq=FALSE)
#Author: Ashish Upadhyay
#Branch: Computer Science and Engineering
#Semester: 6th
#Dr. SP Mukherjee International Institute of Information Technology, Naya Raipur
#Subject: Machine Learning Lab 13
#Task: k-Nearest Neighbour Implementation
setwd("C:/Users/Ashish Upadhyay/Documents/Semester6/MachineLearning/Lab Programs")
getwd()
data_set <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
stringsAsFactors = FALSE
#head(data_set)
nrow(data_set)
str(data_set)
data_set <- data_set[-1]
str(data_set)
table(data_set$diagnosis)
data_set$diagnosis <- as.factor(data_set$diagnosis)
#Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# One could also use sequence such as df[1:2]
dfNorm <- as.data.frame(lapply(data_set[2:31], normalize))
head(dfNorm)
data_train <- dfNorm[1:400,]
data_test <- dfNorm[401:569,]
data_train_labels <- data_set[1:400, 1]
data_test_labels <- data_set[401:569, 1]
#install.packages("class")
library(class)
data_test_pred <- knn(train = data_train, test = data_test,cl = data_train_labels, k=21)
#summary(data_test_pred)
#install.packages("gmodels")
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq=FALSE)
#Z-score standardization
stad <- function(x) {
return ((x - mean(x)) / sqrt(var(x)))
}
# One could also use sequence such as df[1:2]
dfNorm <- as.data.frame(lapply(data_set[2:31], stad))
head(dfNorm)
data_train <- dfNorm[1:400,]
data_test <- dfNorm[401:569,]
data_train_labels <- data_set[1:400, 1]
data_test_labels <- data_set[401:569, 1]
#install.packages("class")
library(class)
data_test_pred <- knn(train = data_train, test = data_test,cl = data_train_labels, k=21)
#summary(data_test_pred)
#install.packages("gmodels")
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq=FALSE)
